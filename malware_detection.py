# -*- coding: utf-8 -*-
"""Malware detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ea8uKe_n3MTA19CWBqqMgbRVrk4Beg73

##Importing
"""

import cv2
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import Model, layers
from random import shuffle
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from tensorflow import keras

from google.colab import drive

drive.mount('/content/gdrive/', force_remount=True)

path_root  = '/content/gdrive/MyDrive/malimg_imgs'

"""To be able to use our images for training and testing, lets use ImageDataGenerator.flow_from_directory() which generates batches of normalized tensor image data from the respective data directories.

target_size : Will resize all images to the specified size. I personally chose (64*64) images.
batch_size : Is the size of the batch we will use. In our case, we only have 9339 images, hence setting a batch_size above this won't change anything.
"""

from keras.preprocessing.image import ImageDataGenerator
batches = ImageDataGenerator().flow_from_directory(directory=path_root, target_size=(64,64), batch_size=10000)

batches.class_indices

"""Batches generated with ImageDataGenerator() is an iterator. Hence, we use next() to go through all its elements and generate a batch of images and labels from the data set."""

imgs, labels = next(batches)

"""As you can see, our images are in RGB with shape 64x64 [width x length x depth]."""

imgs.shape

"""Labels has the shape (batch_size, number of classes)."""

labels.shape

"""The following method allows us to plot a sample of images in our dataset."""

# plots images with labels within jupyter notebook
import matplotlib.pyplot as plt
def plots(ims, figsize=(20,30), rows=10, interp=False, titles=None):
  if type(ims[0]) is np.ndarray:
      ims = np.array(ims).astype(np.uint8)
      if (ims.shape[-1] != 3):
        ims = ims.transpose((0,2,3,1))
  f = plt.figure(figsize=figsize)
  cols = 10 # len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
  for i in range(0,50):
      sp = f.add_subplot(rows, cols, i+1)
      sp.axis('Off')
      if titles is not None:
          sp.set_title(list(batches.class_indices.keys())[np.argmax(titles[i])], fontsize=16)
      plt.imshow(ims[i], interpolation=None if interp else 'none')

plots(imgs, titles = labels)

"""We can already observe differences between classes.

##Analyze

All our images are finally ready to be used. Lets check out the repartition of data between classes :
"""

classes = batches.class_indices.keys()

perc = (sum(labels)/labels.shape[0])*100

plt.xticks(rotation='vertical')
plt.bar(classes,perc)

"""##Train And Test

Lets split our model into train and test following a ratio 70% train - 30% test ratio.
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.3)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""##Convolutional Neural Network Model

We will now build our **CNN** model using Keras. This model will have the following layers :

**Convolutional Laye**r : 30 filters, (3 * 3) kernel size

**Max Pooling Layer** : (2 * 2) pool size

**Convolutional Layer** : 15 filters, (3 * 3) kernel size

**Max Pooling Layer** : (2 * 2) pool size

**DropOut Layer** : Dropping 25% of neurons.

**Flatten Layer**

**Dense/Fully Connected Layer** : 128 Neurons, Relu activation function

**DropOut Layer** : Dropping 50% of neurons.

**Dense/Fully Connected Layer** : 50 Neurons, Softmax activation function

**Dense/Fully Connected Layer** : num_class Neurons, Softmax activation 
function

**Input shape** : 64 * 64 * 3
"""

!pip install tensorflow keras --upgrade

#import keras

#!pip install tensorflow
import tensorflow 
#!pip install keras --upgrade
from keras.models import Sequential,Model
from tensorflow.keras.layers import Input
#from tensorflow.keras.models import Sequential, Input, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization

"""We want 25 classes as output."""

num_classes = 25

def malware_model(ac):
    Malware_model = Sequential()
    Malware_model.add(Conv2D(30, kernel_size=(3, 3),activation=ac,input_shape=(64,64,3)))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
    Malware_model.add(Conv2D(15, (3, 3), activation=ac))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
    Malware_model.add(Dropout(0.25))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(128, activation=ac))
    Malware_model.add(Dropout(0.5))
    Malware_model.add(Dense(50, activation=ac))
    Malware_model.add(Dense(num_classes, activation='softmax'))
    Malware_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
    return Malware_model

"""**We will compare with 10 different activation function**
    
    1. Sigmoid Function

    2.Tanh Function

    3.Leaky ReLU

    4.Exponential Linear Unit (ELU)

    5.Scaled Exponential Linear Unit (SELU)

    6.Gaussian Error Linear Unit (GELU)

    7.Swish

    8.Parametric ReLU

    9.Softplus

##Relu Function
"""

Malware_model = malware_model('relu')

Malware_model.summary()

"""Several methods are available to deal with unbalanced data. I our case, I chose to give higher weight to minority class and lower weight to majority class.

class_weights uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data. To use this method, y_train must not be one hot encoded.
"""

y_train.shape

"""class_weight function cannot deal with one hot encoded y. We need to convert it."""

y_train_new = np.argmax(y_train, axis=1)

y_train_new

!pip install sklearn --upgrade

from sklearn.utils import class_weight
class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

"""We got a **96%** accuracy which is not bad !"""

print('Final CNN accuracy using Relu: ', scores[1])

dic={}
dic['Relu']=0.9635111689567566

acti_list=['sigmoid','tanh','selu','elu','gelu','swish','mish']

"""##Sigmoid Activation Function"""

print("---------------------------------Model using activation function: Sigmoid  ---------------------------------")

Malware_model = malware_model('sigmoid')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Sigmoid: ', scores[1])

dic['Sigmoid']= 0.3287435472011566

"""##Leaky Relu"""

print("---------------------------------Model using activation function: Leaky Relu---------------------------------")

import tensorflow as tf
Malware_model = Sequential()
Malware_model.add(Conv2D(30, kernel_size=(3, 3),activation=tf.keras.layers.LeakyReLU(alpha=0.1),input_shape=(64,64,3)))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Conv2D(15, (3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.1)))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Dropout(0.25))
Malware_model.add(Flatten())
Malware_model.add(Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))
Malware_model.add(Dropout(0.5))
Malware_model.add(Dense(50, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))
Malware_model.add(Dense(num_classes, activation='softmax'))
Malware_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
y_train_new = np.argmax(y_train, axis=1)
class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)
Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Leaky Relu: ', scores[1])

dic['Leaky Relu']=0.9672977328300476

"""## Soft plus"""

print("---------------------------------Model using activation function: Soft Plus---------------------------------")

Malware_model = Sequential()
Malware_model.add(Conv2D(30, kernel_size=(3, 3),activation=tf.nn.softplus,input_shape=(64,64,3)))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Conv2D(15, (3, 3), activation=tf.nn.softplus))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Dropout(0.25))
Malware_model.add(Flatten())
Malware_model.add(Dense(128, activation=tf.nn.softplus))
Malware_model.add(Dropout(0.5))
Malware_model.add(Dense(50, activation=tf.nn.softplus))
Malware_model.add(Dense(num_classes, activation='softmax'))
Malware_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
y_train_new = np.argmax(y_train, axis=1)
class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)
Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Soft plus: ', scores[1])

dic['Soft Plus']=0.9201377034187317

"""##Parametric ReLU"""

print("---------------------------------Model using activation function: Parametric ReLU---------------------------------")

Malware_model = Sequential()
Malware_model.add(Conv2D(30, kernel_size=(3, 3),activation=tf.keras.layers.PReLU(),input_shape=(64,64,3)))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Conv2D(15, (3, 3), activation=tf.keras.layers.PReLU()))
Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
Malware_model.add(Dropout(0.25))
Malware_model.add(Flatten())
Malware_model.add(Dense(128, activation=tf.keras.layers.PReLU()))
Malware_model.add(Dropout(0.5))
Malware_model.add(Dense(50, activation=tf.keras.layers.PReLU()))
Malware_model.add(Dense(num_classes, activation='softmax'))
Malware_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
y_train_new = np.argmax(y_train, axis=1)
class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)
Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Paramatic Plus: ', scores[1])

dic['Paramatic Relu']=0.9666092991828918

"""## Tanh Function"""

print("---------------------------------Model using activation function: Tanh ---------------------------------")

Malware_model = malware_model('tanh')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Tanh: ', scores[1])

dic['Tanh']= 0.9590361714363098

"""##ELU"""

print("---------------------------------Model using activation function: Exponential Linear Unit ---------------------------------")

Malware_model = malware_model('elu')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using ELU: ', scores[1])

dic['Sigmoid']= 0.9562822580337524

"""##Scaled Exponential Linear Unit"""

print("---------------------------------Model using activation function: Scaled Exponential Linear Unit ---------------------------------")

Malware_model = malware_model('selu')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Selu: ', scores[1])

dic['Selu']= 0.9528399109840393

"""## Gaussian Error Linear Unit"""

print("---------------------------------Model using activation function: Gelu ---------------------------------")

Malware_model = malware_model('gelu')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using gelu: ', scores[1])

dic['Gelu']= 0.9697074294090271

"""##Swish"""

print("---------------------------------Model using activation function: Swish ---------------------------------")

Malware_model = malware_model('swish')

y_train_new = np.argmax(y_train, axis=1)

class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train_new),y=y_train_new)

Malware_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)

scores = Malware_model.evaluate(X_test, y_test)

print('Final CNN accuracy using Swish: ', scores[1])

dic['swish']= 0.9597246050834656

"""##Comparision"""

print("Accuracy of the same model with different activation function")

for key in dic:
   print(key,": ",dic[key])
   print()

print("Maximum Accuracy of ",dic['Gelu']," was obtained by using activation function as Gaussian Error Linear Unit (GELU)")